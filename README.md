# Artificial-Intelligence-Algorithms

This repository stores custom implementations of AI algorithms from an Artificial Intelligence course in my graduate program. For learning purposes, these implementations use only the depencencies in the `requirements.yml` file. The `Artificial_Neural_Network` notebook was the only assignment that allowed the use of `numpy`. Many other solutions could be optimized using `pandas` and `numpy`. The goal of this course was to implement these algorithms from scratch and demonstrate their functionalities. Therefore, simple and well-cleaned datasets were used to test the machine learning algorithms in this repository. 

## Requirements

- Install [Anaconda](https://www.anaconda.com/download)
- Run `conda env create -f environment.yml` to create an environment with the necessary dependencies. 


## Algorithms

The following section provides a summary of the algorithms in each notebook. See the function documentation within each notebook for more details about each algorithm.

- **Backtracking and Forward Checking Algorithm**: The [BTFC notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/BTFC_Algorithm.ipynb) contains my implementation of the Backtracking and Forward Checking algorithm and tests the algorithm on the map coloring problem. The **map coloring** problem is **NP-Complete**. The Backtracking and Forward Checking algorithm works by applying forward checking to eliminate values (for this problem, colors) from other variables (for this problem, cities, states, or countries) if a constraining variable selected the value. The algorithm tracks previous decisions/states and applies backtracking if all assignments fail from the current state. Several heuristic functions for value and variable selection can make the Backtracking and Forward Checking algorithm more efficient by reducing the number of times the algorithm must backtrack. One option for **variable selection** is selecting the variable with the smallest domain first (ie: the minimum number of values left to choose from)[1]. This method is known as the **Minimum Remaining Values** heuristic. Another approach for variable selection is known as the **degree heuristic**, in which the algorithm starts with the variable that participates in the most constraints [1]. An approach for **value selection** is the **least constraining value** heuristic, which selects the value that rules out the fewest values from other variables. The backtracking piece of this algorithm leverages **conflict-directed backjumping** to make backtracking more efficient. Conflict-directed backjumping tracks which variable removed a value from another variable's available choices to determine how far the algorithm must backtrack to remove a conflict.

- **Artificial Neural Network**: The [Artificial_Neural_Network notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Artificial_Neural_Network.ipynb) contains a custom Python implementation of an Artificial Neural Network. The notebook applies the neural network to the problem of identifying which type of terrain surrounds an agent in a grid world.

- **A/* Search**: The [A*_Search notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/A*_Search.ipynb) contains my implementation of the A/* search algorithm. A/* search is a state space search algorithm that uses a heuristic function to predict how far each successor state is from the goal state. This algorithm calculates the value of each state using the formula F(n) = g(n) + h(n), where g(n) is the cost to the current state, and h(n) is the estimated cost to the goal from the current state. A/* search is a complete search algorithm. A/* search is guaranteed to find the optimal path to the goal when the heuristic function is admissible (does not overestimate the true cost to the goal). View the streamlit proof of concept to see how the algorithm works. The code for this proof of concept is in the `A*_Proof_of_Concept` directory.

- **Genetic Algorithm**: The [Genetic_Algorithm notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Genetic_Algorithm.ipynb) contains my implementation of the genetic algorithm. The Genetic Algorithm is a local search and optimization technique inspired by natural selection. The genetic algorithm is based on the theory of evolution in that it applies the "survival of the fittest" method to determine the best-fit parents to use in reproduction for each generation. Population individuals are represented by a phenotype (true value) and genotype (chromosome) encoding. The genotype encoding is used in algorithm operations such as reproduction. The algorithm applies techniques such as crossover and mutation to introduce randomness into the search. Leveraging randomness makes local search algorithms more memory efficient than state space search and helps them to search over continuous space. Unlike state space search algorithms, local search algorithms are not guaranteed to find a solution if one exists.

- **Decision Tree**: The [Decision_Tree notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Decision_Tree.ipynb) contains my implementation of the ID3 (Iterative Dichotomiser 3) algorithm. The ID3 algorithm builds a decision tree using the training data. The algorithm recursively builds the decision tree by calculating the information gain of each remaining attribute to determine the best attribute for the next node. The information gain describes how well each attribute separates class labels. An attribute with perfect information gain has homogenous subgroups for its values. An example of an attribute with perfect information gain is color (3 red yes, 3 blue no). In this example, color perfectly classifies the data because all red values return yes, and all blue values return no.

- **Naive Bayes**: The [Naive_Bayes_Classifier notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Naive_Bayes_Classifier.ipynb) contains my implementation of the Naive Bayes algorithm. Naive Bayes is a supervised machine learning model based on Bayes' Theorem. The algorithm is called "Naive" because it assumes the features are independent. The assumption of feature independence simplifies the training process and makes the algorithm computationally efficient. Naive Bayes Classifiers work well for high-dimensional datasets. Naive Bayes Classifiers are also used as baseline models to compare performance with other classifiers due to their explainability and ease of implementation.

- **SEDS Algorithm**: The [SEDS_Algorithm notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/SEDS_Algorithm.ipynb) contains my implementation of the SEDS algorithm and applies the algorithm to the prisoner's dilemma game (see notebook for game details). The Successive Elimination of Dominated Strategies (SEDS) algorithm is used in game theory to find **pure strategy Nash Equilibriums** for normal-form games. A Nash Equilibrium occurs when neither player can obtain a better outcome by changing their strategy alone. The SEDS algorithm iteratively eliminates dominated strategies for each player to reduce the search space and improve computational efficiency. A dominated strategy can be either strongly dominated or weakly dominated, and the algorithm has a boolean parameter to specify whether it should eliminate weakly dominated strategies. A strongly dominated strategy is one where all payoffs in `strategy a` for the current player are less than all payoffs in `strategy b` for the current player. A weakly dominated strategy is one where all payoffs in `strategy a` for the current player are less than or equal to all payoffs in `strategy b` for the current player. See the notebook for detailed walk-throughs of the SEDS algorithm.

- **Stochastic Value Iteration**: The [Value_Iteration notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/RL_Value_Iteration.ipynb) contains my implementation of the stochastic value iteration algorithm. The stochastic value iteration algorithm is a reinforcement learning algorithm that returns a policy reflecting the best action for every world state, given a goal state. This algorithm handles uncertainty in the world. This notebook demonstrates a problem with uncertainty by incorporating a 10% chance that the agent will move in an unexpected direction. For example, if the agent tries to move north, there is a 10% chance it will go south, east, or west. The value iteration algorithm finds the optimal path to a goal when run until convergence.

- **Forward Planning and Unification**: The [Unification notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Unification_Algorithm.ipynb) implements the unification algorithm that is used by the forward planning algorithm. Unification balances expressions to determine if two S-Expressions are syntactically equivalent. The [Forward_Planner notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/Forward_Planner.ipynb) contains my implementation of the forward planning algorithm. The forward planning algorithm identifies the "plan" with the fewest actions to reach a goal state, given a list of possible states (represented as S-Expressions). The forward planning algorithm works well for scheduling tasks, such as planning an aircraft's route to various destinations.

- **kNN**: The [KNN notebook](https://github.com/S-Spence/Artificial-Intelligence-Algorithms/blob/main/KNN.ipynb) contains my implementation of the k Nearest Neighbors algorithm. K Nearest Neighbors is a distance-based algorithm that aims to minimize the distance between observations to identify the k observations that are most similar to the test example. There are several different choices for the distance metrics, and this selection depends on the problem. Some common examples of distance metrics are the Euclidean distance, the Manhattan distance, and the Hamming distance. kNN is considered "lazy learning" because it does not build a model [1]. This algorithm works well for low-dimensional datasets with many observations.



### References

[1] S. Russel and P, Norvig. "Artificial Intelligence A Modern Approach, Fourth Edition," Pearson Education Inc, 2021. 
