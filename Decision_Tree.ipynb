{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from typing import List, Dict, Callable, Tuple, Any\n",
    "from math import log2\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the mushrooms [datatset](http://archive.ics.uci.edu/ml/datasets/Mushroom).\n",
    "\n",
    "The following notebook implements a custom decision tree using the ID3 algorithm and tests the model on the mushroom dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creat_folds\"></a>\n",
    "## create_folds\n",
    "*The create_folds function is a helper function that splits the data into n test sets.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[Any]: the dataset\n",
    "* **n** int: the number of folds\n",
    "\n",
    "**returns** Tuple[List[List], List[List]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by S. butcher, 2022\n",
    "def create_folds(data: List[Any], n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    # be careful of generators...\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creat_train_test\"></a>\n",
    "## create_train_test\n",
    "*The create_train_test function is a helper that returns the training and test splits for the provided fold index.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **folds** List[List[List[str]]]: the folds created by [create_folds](#create_folds)\n",
    "* **index** Dict[str, str]: the index of the fold to use for the test set\n",
    "\n",
    "**returns** Tuple[List[List], List[List]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by S. butcher, 2022\n",
    "def create_train_test(folds: List[List[List[str]]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split_labels\"></a>\n",
    "## split_labels\n",
    "*The split_labels function is a helper function to separate the labels from the data.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[List[str]]: the data with labels\n",
    "* **label_index** int: the index of the label\n",
    "\n",
    "**returns** Tuple[List[str], List[List[str]]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(data: List[List[str]], label_index: int) -> Tuple[List[str], List[List[str]]]:\n",
    "    values = [row[:label_index] + row[label_index+1:] for row in data]\n",
    "    labels = [row[label_index] for row in data]\n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"majority_label\"></a>\n",
    "## majority_label\n",
    "*The majority_label function takes a list of labels and returns the value that occurs most frequently.* **Used by**: [id3](#id3)\n",
    "\n",
    "* **data_labels** List[str]: the data labels\n",
    "\n",
    "**returns** str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_label(data_labels: List[str]) -> str:\n",
    "    majority = \"\"\n",
    "    max_count = 0\n",
    "    classes = set(data_labels)\n",
    "    for element in classes:\n",
    "        count = data_labels.count(element)\n",
    "        if count > max_count:\n",
    "            majority = element\n",
    "            max_count = count\n",
    "    return majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assertions/unit tests\n",
    "test_labels_1 = [\"y\", \"n\", \"y\", \"n\", \"y\"]\n",
    "\n",
    "assert majority_label(test_labels_1) == \"y\"\n",
    "\n",
    "# even split, return either \n",
    "test_labels_2 = [\"y\", \"n\", \"y\", \"n\"]\n",
    "\n",
    "assert majority_label(test_labels_2) == \"y\" or \"n\"\n",
    "\n",
    "assert majority_label([\"n\"]) == \"n\"\n",
    "\n",
    "assert majority_label([]) == \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_subset\"></a>\n",
    "## get_subset\n",
    "*The get_subset function takes a dataset, a list of labels, the attribute index, and a value. The function returns a subset containing values for which the attribute index is equal to the value. The function also returns the updated labels for the subset. The function removes the current attribute from the subset because the id3 algorithm will not use it for calculations on the subset.* **Used by**: [id3](#id3)\n",
    "\n",
    "* **data** List[List[[str]]: the data\n",
    "* **labels** List[[str]: the data labels\n",
    "* **attibute_index** int: the index of the attribute for the subset\n",
    "* **value** str: the attribute value for the subset\n",
    "\n",
    "**returns** Tuple[List[List[str]], List[str]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(data: List[List[str]], labels: List[str], attribute_index: int, value: str) -> Tuple[List[List[str]], List[str]]:\n",
    "    subset = []\n",
    "    subset_labels = []\n",
    "    for index, row in enumerate(data):\n",
    "        if row[attribute_index] == value:\n",
    "            subset.append(row[:attribute_index] + row[attribute_index+1:])\n",
    "            subset_labels.append(labels[index])\n",
    "    return [subset, subset_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    [\"red\", \"round\", \"large\"],\n",
    "    [\"blue\", \"round\", \"large\"],\n",
    "    [\"green\", \"square\", \"small\"],\n",
    "    [\"red\", \"square\", \"small\"],\n",
    "    [\"green\", \"round\", \"large\"],\n",
    "]\n",
    "\n",
    "test_labels = [\"yes\", \"no\", \"yes\", \"no\", \"no\"]\n",
    "\n",
    "# should remove the best attribute from the subset\n",
    "assert get_subset(test_data, test_labels, 0, \"red\") == [[[\"round\", \"large\"], [\"square\", \"small\"]], [\"yes\", \"no\"]]\n",
    "assert get_subset(test_data, test_labels, 1, \"square\") == [[[\"green\", \"small\"], [\"red\", \"small\"]], [\"yes\", \"no\"]]\n",
    "assert get_subset(test_data, test_labels, 2, \"small\") == [[[\"green\", \"square\"], [\"red\", \"square\"]], [\"yes\", \"no\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_entropy\"></a>\n",
    "## get_entropy\n",
    "*The get_entropy function takes a list of labels and returns the entropy. Entropy describes how evenly distributed the data is in terms of class labels. This value is used to calculate the information gain of each attribute. The information gain describes how well an attribute separates classes.* **Used by**: [get_best_attribute](#get_best_attribute), [get_weighted_entropy](#get_weighted_entropy)\n",
    "\n",
    "* **labels** List[[str]: the data labels\n",
    "\n",
    "**returns** float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(labels: List[str]) -> float:\n",
    "    unique_classes = set(labels)\n",
    "    entropy = 0\n",
    "    # get the entropy for each class type and subtract from the total entropy\n",
    "    for class_type in unique_classes:\n",
    "        class_count = labels.count(class_type)\n",
    "        if class_count == len(labels) or class_count == 0:\n",
    "            # entropy is 0 for either case, no need to add to the calculation\n",
    "            continue\n",
    "        # subtract the class entropy from the total entropy\n",
    "        entropy -= class_count/len(labels) * log2(class_count/len(labels))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_labels_1 = [\"y\", \"n\", \"y\", \"n\", \"y\", \"y\", \"y\", \"y\"]\n",
    "\n",
    "assert round(get_entropy(test_labels_1), 2) == 0.81\n",
    "\n",
    "test_labels_2 = [\"n\", \"n\"]\n",
    "\n",
    "assert get_entropy(test_labels_2) == 0\n",
    "\n",
    "test_labels_3 = [\"y\", \"n\"]\n",
    "\n",
    "assert get_entropy(test_labels_3) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_weighted_entropy\"></a>\n",
    "## get_weighted_entropy\n",
    "*The get_weighted_entropy function takes a subset containing data for a specific attribute, the attribute index, and the label index. The function returns the weighted entropy of the attribute. The weighted entropy is calculated by calculating the entropy for each of the feature's values and multiplying this value by the proportion of each value. The weighted entropy is the sum of these results. For example, if there are 3 red examples (1 positive, 2 negative) and 5 blue examples (3 positive, 2 negative), the algorithm would calculate weighted entropy as follows:*\n",
    "Entropy Red: -1/3 *log2(1/3) - 2/3 * log2(2/3)\n",
    "Entropy Blue: -3/5 * log2(3/5) - 2/5 * log2(2/5)\n",
    "Weighted Entropy: 3/8(Entropy Red) + 5/8(Entropy Blue)\n",
    "\n",
    "*The weighted entropy is used to calculate the information gain for a feature.*\n",
    "**Used by**: [get_best_attribute](#get_best_attribute)\n",
    "\n",
    "* **attribute_data** List[List[str]]: the attribute subset\n",
    "* **attribute_index** int: the index of the attribute in the subset\n",
    "* **label_index** int: the index of the label in the subset\n",
    "  \n",
    "**returns** float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_entropy(attribute_data: List[List[str]], attribute_index: int, label_index: int) -> float:\n",
    "    unique_values = set([row[attribute_index] for row in attribute_data])\n",
    "    weighted_entropy = 0\n",
    "    for value_type in unique_values:\n",
    "        value_subset = [row for row in attribute_data if row[attribute_index] == value_type]\n",
    "        # calculate the entropy for each value in the attribute subset\n",
    "        entropy = get_entropy([row[label_index] for row in value_subset])\n",
    "        # calculate the weighted entropy by summing the proportion * entropy for each value\n",
    "        weighted_entropy += entropy * len(value_subset)/len(attribute_data)   \n",
    "    return weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_attribute_data_1 = [[\"no\", \"blue\"], [\"yes\", \"green\"], [\"no\", \"red\"], [\"yes\", \"red\"], \n",
    "                        [\"no\", \"blue\"], [\"no\", \"blue\"], [\"yes\", \"red\"], [\"no\", \"green\"], \n",
    "                        [\"yes\", \"green\"], [\"yes\", \"green\"], [\"no\", \"red\"], [\"yes\", \"green\"],\n",
    "                        [\"yes\", \"red\"], [\"no\", \"red\"], [\"no\", \"green\"]]\n",
    "\n",
    "round(get_weighted_entropy(test_attribute_data_1, 1, 0), 2)# == 0.77\n",
    "\n",
    "# homogenous data split, should return 0\n",
    "test_attribute_data_2 = [[\"yes\", \"blue\"], [\"no\", \"green\"], [\"no\", \"red\"], [\"no\", \"red\"], \n",
    "                        [\"yes\", \"blue\"], [\"yes\", \"blue\"], [\"no\", \"red\"], [\"no\", \"green\"]]\n",
    "\n",
    "assert round(get_weighted_entropy(test_attribute_data_2, 1, 0), 2) == 0.00\n",
    "\n",
    "# data evenly distributed, should return 1\n",
    "test_attribute_data_3 = [[\"no\", \"blue\"], [\"no\", \"blue\"], [\"yes\", \"red\"], [\"yes\", \"red\"], \n",
    "                        [\"yes\", \"blue\"], [\"yes\", \"blue\"], [\"no\", \"red\"], [\"no\", \"red\"]]\n",
    "\n",
    "assert round(get_weighted_entropy(test_attribute_data_3, 1, 0), 2) == 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_best_attribute\"></a>\n",
    "## get_best_attribute\n",
    "*The get_best_attribute function calculates the information gain for each attribute by subtracting the weighted entropy from the initial entropy for the subset or dataset. The information gain describes how well each attribute separates class labels. An attribute with perfect information gain has homogenous subgroups for its values. An example of an attribute with perfect information gain is color (3 red yes, 3 blue no). In this example, color perfectly classifies the data because all red values return yes, and all blue values return no. The function returns the attribute with the highest information gain.*\n",
    "**Used by**: [id3](#id3)\n",
    "\n",
    "* **data** List[List[str]]: the dataset or subset\n",
    "* **labels** List[str]: the labels for the dataset or subset\n",
    "* **attributes** List[str]: the available attributes in the data or subset (excluding labels)\n",
    "  \n",
    "**returns** str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_attribute(data: List[List[str]], labels: List[str], attributes: List[str]) -> str:\n",
    "    information_gains = []\n",
    "    # calculate the information gain for each attribute and add to the list\n",
    "    for index, attribute in enumerate(attributes):\n",
    "        attribute_data = [[labels[row_index], row[index]] for row_index, row in enumerate(data)]\n",
    "        initial_entropy = get_entropy(labels)\n",
    "        weighted_entropy = get_weighted_entropy(attribute_data, 1, 0)\n",
    "        information_gains.append(initial_entropy - weighted_entropy)\n",
    "    # get the best attribute and best attribute index\n",
    "    best_attribute_gain = max(information_gains)\n",
    "    best_attribute_index = information_gains.index(best_attribute_gain)\n",
    "    return best_attribute_index, attributes[best_attribute_index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_data_1 = [\n",
    "    [\"round\", \"large\", \"blue\"],\n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"red\"],  \n",
    "    [\"square\", \"small\", \"green\"],  \n",
    "    [\"round\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"red\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"small\", \"green\"]\n",
    "]\n",
    "test_labels_1 = [\"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"no\"]\n",
    "test_attributes_1 = [\"shape\", \"size\", \"color\"]\n",
    "\n",
    "assert get_best_attribute(test_data_1, test_labels_1, test_attributes_1) == (1, \"size\")\n",
    "\n",
    "# subset small\n",
    "test_data_2 = [\n",
    "    [\"square\", \"red\"],  \n",
    "    [\"square\", \"blue\"],  \n",
    "    [\"round\", \"blue\"],  \n",
    "    [\"round\", \"red\"],  \n",
    "    [\"square\", \"green\"],  \n",
    "    [\"square\", \"red\"],  \n",
    "    [\"round\", \"green\"]\n",
    "]\n",
    "test_labels_2 = [\"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\"]\n",
    "test_attributes_2 = [\"shape\", \"color\"]\n",
    "\n",
    "# choose first attribute for a tie\n",
    "assert get_best_attribute(test_data_2, test_labels_2, test_attributes_2) == (0, \"shape\")\n",
    "\n",
    "# subset large\n",
    "test_data_3 = [\n",
    "    [\"round\", \"blue\"],\n",
    "    [\"square\", \"green\"],  \n",
    "    [\"round\", \"red\"],   \n",
    "    [\"round\", \"green\"],  \n",
    "    [\"square\",\"green\"],  \n",
    "    [\"square\", \"red\"],  \n",
    "    [\"square\", \"green\"],  \n",
    "    [\"round\", \"red\"] \n",
    "]\n",
    "test_labels_3 = [\"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\"]\n",
    "test_attributes_3 = [\"shape\", \"color\"]\n",
    "\n",
    "assert get_best_attribute(test_data_3, test_labels_3, test_attributes_3) == (1, \"color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "## id3\n",
    "*The id3 algorithm (Iterative Dichotomiser 3) builds a decision tree using the training data. The id3 algorithm is a recursive algorithm that builds the tree by calculating the information gain of each remaining attribute to determine the best attribute for the next node (See [get_best_attribute](#get_best_attribute)). Classification functions can use this decision tree to predict future values. The function takes an optional depth_limit parameter. Applying a depth limit can help correct overfitting. The function returns the tree as nested dictionaries.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[List[str]]: the training dataset\n",
    "* **data_labels** List[str]: the labels for the dataset\n",
    "* **attributes** List[str]: the attributes in the dataset (excluding class label)\n",
    "* **default** str: the majority class label\n",
    "* **current_depth** int: the current depth of the tree\n",
    "* **depth_limit** int: the depth limit\n",
    "\n",
    "**returns** Dict[str, Any]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data: List[List[str]], data_labels: List[str], attributes: List[str], default: str, current_depth: int, depth_limit: int = None) -> Dict[str, Any]:\n",
    "    if len(data) == 0:\n",
    "        return default\n",
    "    if len(set(data_labels)) == 1:\n",
    "        return data_labels[0]\n",
    "    if len(attributes) == 0 or current_depth == depth_limit:\n",
    "        return majority_label(data_labels)\n",
    "    # get best attribute, majority class, and attribute domain\n",
    "    best_attribute_index, best_attribute = get_best_attribute(data, data_labels, attributes)\n",
    "    node = {best_attribute: {}}\n",
    "    default_label = majority_label(data_labels)\n",
    "    attribute_domain = set([row[best_attribute_index] for row in data])\n",
    "    # call id3 recursively for each value in the best attribute's domain\n",
    "    for value in attribute_domain:\n",
    "        value_subset, subset_labels = get_subset(data, data_labels, best_attribute_index, value)\n",
    "        new_attributes = deepcopy(attributes)\n",
    "        new_attributes.remove(best_attribute)\n",
    "        child = id3(value_subset, subset_labels, new_attributes, default_label, current_depth+1, depth_limit)\n",
    "        node[best_attribute][value] = child\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_data_1 = [\n",
    "    [\"round\", \"large\", \"blue\"],\n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"red\"],  \n",
    "    [\"square\", \"small\", \"green\"],  \n",
    "    [\"round\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"red\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"small\", \"green\"]\n",
    "]\n",
    "\n",
    "test_labels_1 = [\"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"no\"]\n",
    "test_attributes = [\"shape\", \"size\", \"color\"]\n",
    "\n",
    "expected_tree_1 = {'size': \n",
    "                   {'small': \n",
    "                    {'shape': \n",
    "                     {'round': \n",
    "                      {'color': \n",
    "                       {'green': 'no', \n",
    "                        'blue': 'no', \n",
    "                        'red': 'yes'}}, \n",
    "                      'square': 'no'}}, \n",
    "                    'large': \n",
    "                    {'color': \n",
    "                     {'green': 'yes', \n",
    "                      'blue': 'no', \n",
    "                      'red': \n",
    "                      {'shape': \n",
    "                       {'round': 'yes', \n",
    "                        'square': 'no'}}}}}}\n",
    "\n",
    "assert id3(test_data_1, test_labels_1, test_attributes, \"no\", 0, None) == expected_tree_1\n",
    "# test with depth limit of 0\n",
    "assert id3(test_data_1, test_labels_1, test_attributes, \"no\", 0, 0) == 'no'\n",
    "# test with depth limit of 1\n",
    "assert id3(test_data_1, test_labels_1, test_attributes, \"no\", 0, 1) == {'size': {'small': 'no', 'large': 'yes'}}\n",
    "# test with depth limit of 2\n",
    "expected_tree_2 = {'size': \n",
    "                   {'small': \n",
    "                    {'shape': \n",
    "                     {'round': 'no', \n",
    "                      'square': 'no'}}, \n",
    "                    'large': {\n",
    "                        'color': \n",
    "                          {'green': 'yes', \n",
    "                           'blue': 'no', \n",
    "                           'red': 'yes'}}}}\n",
    "assert id3(test_data_1, test_labels_1, test_attributes, \"no\", 0, 2) == expected_tree_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify_observation\"></a>\n",
    "## classify_observation\n",
    "*The classify_observation algorithm searches a decision tree recursively to find the classification for a single observation.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **current_node** Dict[str, Any] | str: the current tree or subtree to search\n",
    "* **observation** List[str]: the labeled or unlabeled observation to classify\n",
    "* **attributes** List[str]: the attributes in the dataset (excluding class label)\n",
    "\n",
    "**returns** str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_observation(current_node: Dict[str, Any] | str, observation: List[str], attributes: List[str]) -> str:\n",
    "    # return when hitting a leaf node \n",
    "    if not isinstance(current_node, dict):\n",
    "        return current_node\n",
    "\n",
    "    # get the current attribute and its values from the decision tree\n",
    "    attribute, attribute_values = list(current_node.items())[0]\n",
    "    attribute_index = attributes.index(attribute)\n",
    "    \n",
    "    # get the value of the attribute for this observation\n",
    "    attribute_value = observation[attribute_index]\n",
    "    \n",
    "    # get the subtree for this attribute value\n",
    "    subtree = attribute_values.get(attribute_value)\n",
    "\n",
    "    return classify_observation(subtree, observation, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = {'size': \n",
    "                   {'small': \n",
    "                    {'shape': \n",
    "                     {'round': \n",
    "                      {'color': \n",
    "                       {'green': 'no', \n",
    "                        'blue': 'no', \n",
    "                        'red': 'yes'}}, \n",
    "                      'square': 'no'}}, \n",
    "                    'large': \n",
    "                    {'color': \n",
    "                     {'green': 'yes', \n",
    "                      'blue': 'no', \n",
    "                      'red': \n",
    "                      {'shape': \n",
    "                       {'round': 'yes', \n",
    "                        'square': 'no'}}}}}}\n",
    "\n",
    "test_attributes = [\"shape\", \"size\", \"color\"]\n",
    "# assertions/unit tests\n",
    "assert classify_observation(test_tree, [\"round\", \"large\", \"green\"], test_attributes) == \"yes\"\n",
    "assert classify_observation(test_tree, [\"round\", \"small\", \"green\"], test_attributes) == \"no\"\n",
    "assert classify_observation(test_tree, [\"square\", \"large\", \"green\"], test_attributes) == \"yes\"\n",
    "# unseen example with the knowledge that blue is always no\n",
    "assert classify_observation(test_tree, [\"square\", \"large\", \"blue\"], test_attributes) == \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "*The classify function takes a list of labeled or unlabeled data and returns predictions by calling [classify_observation](#classify_observation) for each value.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **decision tree** Dict[str, Any] | str: a decision tree represented as nested dictionaries\n",
    "* **observations** List[List[str]]: the labeled or unlabeled observations to classify\n",
    "* **attributes** List[str]: the attributes in the dataset (excluding class label)\n",
    "\n",
    "**returns** str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(decision_tree: Dict[str, Any], observations: List[List[str]], attributes: List[str]):\n",
    "    classifications = []\n",
    "    for observation in observations:\n",
    "        predicition = classify_observation(decision_tree, observation, attributes)\n",
    "        classifications.append(predicition)\n",
    "    return classifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_tree = {'size': \n",
    "                   {'small': \n",
    "                    {'shape': \n",
    "                     {'round': \n",
    "                      {'color': \n",
    "                       {'green': 'no', \n",
    "                        'blue': 'no', \n",
    "                        'red': 'yes'}}, \n",
    "                      'square': 'no'}}, \n",
    "                    'large': \n",
    "                    {'color': \n",
    "                     {'green': 'yes', \n",
    "                      'blue': 'no', \n",
    "                      'red': \n",
    "                      {'shape': \n",
    "                       {'round': 'yes', \n",
    "                        'square': 'no'}}}}}}\n",
    "\n",
    "test_attributes = [\"shape\", \"size\", \"color\"]\n",
    "predictions_1 = classify(test_tree, [[\"round\", \"large\", \"green\"], [\"round\", \"small\", \"green\"], [\"square\", \"large\", \"green\"]], test_attributes)\n",
    "assert predictions_1 == [\"yes\", \"no\" , \"yes\"]\n",
    "\n",
    "predictions_2 = classify(test_tree, [[\"round\", \"large\", \"blue\"], [\"square\", \"large\", \"green\"]], test_attributes)\n",
    "assert predictions_2 == [\"no\" , \"yes\"]\n",
    "\n",
    "predictions_3 = classify(test_tree, [[\"square\", \"large\", \"blue\"], [\"round\", \"small\", \"blue\"]], test_attributes)\n",
    "assert predictions_3 == [\"no\" , \"no\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"error_rate\"></a>\n",
    "## error_rate\n",
    "*The error_rate function takes a list of predictions and a list of true values and returns the error rate of the predictions using the formula incorrect_predicitions/total_predictions.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **predictions** List[str]: the predictions for a classification task\n",
    "* **labels** List[str]: the true class values\n",
    "\n",
    "**returns** float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions: List[str], labels: List[str]) -> float:\n",
    "    total = len(predictions)\n",
    "    incorrect = sum(pred != true_value for pred, true_value in zip(predictions, labels))\n",
    "    return incorrect / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "classifications_1 = [\"yes\", \"no\", \"yes\"]\n",
    "labels_1 = [\"yes\", \"no\", \"yes\"]\n",
    "\n",
    "assert error_rate(classifications_1, labels_1) == 0.00\n",
    "\n",
    "classifications_2 = [\"yes\", \"yes\", \"yes\"]\n",
    "labels_2 = [\"no\", \"no\", \"no\"]\n",
    "\n",
    "assert error_rate(classifications_2, labels_2) == 1.00\n",
    "\n",
    "classifications_3 = [\"no\", \"no\", \"yes\", \"yes\"]\n",
    "labels_3 = [\"no\", \"no\", \"no\", \"no\"]\n",
    "\n",
    "assert error_rate(classifications_3, labels_3) == 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k_fold_validation\"></a>\n",
    "## k_fold_validation\n",
    "\n",
    "*The k_fold_validation function applies k-fold validation on the dataset and prints the average error and error variance of the training and test set for each run. The algorithm returns the average error and the error variance for the training and test sets. The function also prints these values. The k-fold validation algorithm works by sampling k unique test samples from the dataset and using the rest of the data for a training set. This algorithm helps evaluate small datasets.*\n",
    "\n",
    "* **model_function** Callable: the algorithm for the model\n",
    "* **classify_function** Callable: the classification function\n",
    "* **eval_function** Callable: the evaluation function\n",
    "* **label_index** int: the label index in the dataset\n",
    "* **folds** List[List[List[str]]]: the k folds to evaluate\n",
    "* **attributes** List[str]: the data attributes (excluding class label)\n",
    "* **depth_limit**: (optional) The depth limit for the decision tree (defaults to None)\n",
    "\n",
    "**returns** Tuple[Any]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(model_function: Callable, classify_function: Callable, eval_function: Callable, label_index: int, folds: List[List[List[str]]], attributes: List[str], depth_limit:int=None) -> Tuple[Any]:\n",
    "    total_train_loss, total_test_loss = 0, 0\n",
    "    train_losses, test_losses = [], []\n",
    "    for index in range(len(folds)):\n",
    "        # split data and labels\n",
    "        train, test = create_train_test(folds, index)\n",
    "        train_examples, train_labels = split_labels(train, label_index)\n",
    "        test_examples, test_labels = split_labels(test, label_index)\n",
    "        # create decision tree with the training data\n",
    "        default_train_label = majority_label(train_labels)\n",
    "        decision_tree = model_function(train_examples, train_labels, attributes, default_train_label, 0, depth_limit)\n",
    "\n",
    "        train_predictions = classify_function(decision_tree, train_examples, attributes)\n",
    "        train_loss = eval_function(train_predictions, train_labels)\n",
    "        test_predictions = classify_function(decision_tree, test_examples, attributes)\n",
    "        test_loss = eval_function(test_predictions, test_labels)\n",
    "        print(f\"Fold: {index+1}, train loss: {train_loss*100}%, test loss: {test_loss*100}%\")\n",
    "        total_train_loss  += train_loss\n",
    "        train_losses.append(train_loss)\n",
    "        total_test_loss  += test_loss\n",
    "        test_losses.append(test_loss)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"Average Train Loss: {(total_train_loss/len(folds)) * 100}%, Train Loss Variance: {np.var(train_losses)}\")\n",
    "    print(f\"Average Test Loss: {(total_test_loss/len(folds)) * 100}%, Test Loss Variance: {np.var(test_losses)}\")\n",
    "    return total_train_loss/len(folds), np.var(train_losses), total_test_loss/len(folds), np.var(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train loss: 0.0%, test loss: 50.0%\n",
      "Fold: 2, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 3, train loss: 0.0%, test loss: 50.0%\n",
      "Fold: 4, train loss: 0.0%, test loss: 50.0%\n",
      "Fold: 5, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 6, train loss: 0.0%, test loss: 100.0%\n",
      "Fold: 7, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 8, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 9, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 10, train loss: 0.0%, test loss: 0.0%\n",
      "---------------------------------------------------\n",
      "Average Train Loss: 0.0%, Train Loss Variance: 0.0\n",
      "Average Test Loss: 25.0%, Test Loss Variance: 0.1125\n"
     ]
    }
   ],
   "source": [
    "# assertions/unit tests\n",
    "test_data = [\n",
    "    [\"round\", \"large\", \"blue\", \"no\"],\n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"red\", \"no\"],  \n",
    "    [\"round\", \"large\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"blue\", \"no\"],  \n",
    "    [\"round\", \"small\", \"blue\", \"no\"],  \n",
    "    [\"round\", \"small\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"green\", \"no\"],  \n",
    "    [\"round\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"large\", \"red\", \"no\"],  \n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"round\", \"large\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"red\", \"no\"],  \n",
    "    [\"round\", \"small\", \"green\", \"no\"]\n",
    "]\n",
    "\n",
    "folds = create_folds(test_data, 10)\n",
    "average_train_error, train_variance,  average_test_error, test_variance = k_fold_validation(id3, classify, error_rate, 3, folds, test_attributes)\n",
    "\n",
    "# assetions\n",
    "assert average_train_error == 0.00\n",
    "assert average_test_error == 0.25\n",
    "assert train_variance == 0.00\n",
    "assert test_variance ==  0.1125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Validation on the Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column labels\n",
    "col_names = [\"label\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises?\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \n",
    "             \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\",\n",
    "            \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"]\n",
    "# read in data\n",
    "def read_data(filename, delimiter):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.strip().split(delimiter) for line in f]\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "data = read_data('Datasets/agaricus-lepiota.data', \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 2, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 3, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 4, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 5, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 6, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 7, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 8, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 9, train loss: 0.0%, test loss: 0.0%\n",
      "Fold: 10, train loss: 0.0%, test loss: 0.0%\n",
      "---------------------------------------------------\n",
      "Average Train Loss: 0.0%, Train Loss Variance: 0.0\n",
      "Average Test Loss: 0.0%, Test Loss Variance: 0.0\n"
     ]
    }
   ],
   "source": [
    "new_folds = create_folds(data, 10)\n",
    "averge_train_error, train_variance, averge_test_error, test_variance = k_fold_validation(id3, classify, error_rate, 0, new_folds, col_names[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Using the Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(tree, indent=\"\"):\n",
    "    if isinstance(tree, dict):\n",
    "        for key, value in tree.items():\n",
    "            print(indent + \"|--\" + key)\n",
    "            pretty_print_tree(value, indent + \"   \")\n",
    "    else:\n",
    "        print(indent + \"  \" + tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--odor\n",
      "   |--p\n",
      "        p\n",
      "   |--f\n",
      "        p\n",
      "   |--a\n",
      "        e\n",
      "   |--l\n",
      "        e\n",
      "   |--n\n",
      "      |--spore-print-color\n",
      "         |--o\n",
      "              e\n",
      "         |--r\n",
      "              p\n",
      "         |--n\n",
      "              e\n",
      "         |--y\n",
      "              e\n",
      "         |--k\n",
      "              e\n",
      "         |--w\n",
      "            |--habitat\n",
      "               |--p\n",
      "                    e\n",
      "               |--l\n",
      "                  |--cap-color\n",
      "                     |--w\n",
      "                          p\n",
      "                     |--n\n",
      "                          e\n",
      "                     |--y\n",
      "                          p\n",
      "                     |--c\n",
      "                          e\n",
      "               |--g\n",
      "                    e\n",
      "               |--w\n",
      "                    e\n",
      "               |--d\n",
      "                  |--gill-size\n",
      "                     |--n\n",
      "                          p\n",
      "                     |--b\n",
      "                          e\n",
      "         |--b\n",
      "              e\n",
      "         |--h\n",
      "              e\n",
      "   |--y\n",
      "        p\n",
      "   |--m\n",
      "        p\n",
      "   |--s\n",
      "        p\n",
      "   |--c\n",
      "        p\n"
     ]
    }
   ],
   "source": [
    "new_data = [row[1:] for row in data]\n",
    "labels = [row[0] for row in data]\n",
    "tree = id3(new_data, labels, col_names[1:], \"p\", 0)\n",
    "pretty_print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the decision tree learned to classify the mushroom dataset perfectly. However, this model might not generalize well to mushroom datasets with different features or new species of mushrooms. Setting a depth limit can help prevent overfitting by model. Validation curves could help identify the best depth limit for the id3 algorithm and the mushroom classification problem. Validation curves work by running k-fold validation on many depth limits (ex: 1-10) and plotting the results for each depth limit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
