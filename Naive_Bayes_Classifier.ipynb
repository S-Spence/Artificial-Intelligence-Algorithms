{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Tuple, Callable\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [mushroom dataset](http://archive.ics.uci.edu/ml/datasets/Mushroom). \n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "Apply the Naive Bayes Classifier algorithm to the Mushroom data set using 10 fold cross validation and the error rate as the evaluation metric. Test with and without smoothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creat_folds\"></a>\n",
    "## create_folds\n",
    "*The create_folds function is a helper function that splits the data into n test sets.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[Any]: the dataset\n",
    "* **n** int: the number of folds\n",
    "\n",
    "**returns** Tuple[List[List], List[List]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by s. Butcher, 2022\n",
    "def create_folds(data: List[Any], n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    # be careful of generators...\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creat_train_test\"></a>\n",
    "## create_train_test\n",
    "*The create_train_test function is a helper that returns the training and test splits for the provided fold index.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **folds** List[List[List[str]]]: the folds created by [create_folds](#create_folds)\n",
    "* **index** Dict[str, str]: the index of the fold to use for the test set\n",
    "\n",
    "**returns** Tuple[List[List], List[List]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by S. butcher, 2022\n",
    "def create_train_test(folds: List[List[List[str]]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split_labels\"></a>\n",
    "## split_labels\n",
    "*The split_labels function is a helper function to separate the labels from the data.* **Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[List[str]]: the data with labels\n",
    "* **label_index** int: the index of the label\n",
    "\n",
    "**returns** Tuple[List[str], List[List[str]]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(data: List[List[str]], label_index: int) -> Tuple[List[str], List[List[str]]]:\n",
    "    values = [row[:label_index] + row[label_index+1:] for row in data]\n",
    "    labels = [row[label_index] for row in data]\n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train_naive_bayes\"></a>\n",
    "## train_naive_bayes\n",
    "*The train_naive_bayes function calculates the probabilities for a Naive Bayes Classifier. The function stores these probabilities in nested dictionaries. The outer dictionary keys are the class labels. The dictionary values are nested dictionaries, where key \"c\" is the class probability, and the rest of the keys are attributes. The attribute keys map to nested dictionaries of attribute values storing the conditional probability of each attribute value given the class label. The class probability is known as the prior probability, and the conditional probabilities are known as the posterior probabilities. The [classifier_observation](#classify_observation) function uses these class probabilities and conditional probabilities to classify unseen examples. See the unit tests below for an example of the output format.*\n",
    "\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **data** List[List[str]]: nested lists containing rows of training data with the labels removed\n",
    "* **labels** List[str]: the labels for the training data\n",
    "* **attributes** List[str]: the dataset attributes with the label name removed\n",
    "* **smoothing** bool: an optional boolean specifying if the train function should apply +1 smoothing when calculating conditional probabilities. The default value is True.\n",
    "\n",
    "**returns** Dict[str, float | Any]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(data: List[List[str]], labels: List[str], attributes:List[str], smoothing:bool=True) -> Dict[str, float | Any]:\n",
    "    smoothing_factor = 1 if smoothing == True else 0 \n",
    "    unique_labels = set(labels)\n",
    "    output = {}\n",
    "    \n",
    "    for class_type in unique_labels:\n",
    "        class_count = labels.count(class_type)\n",
    "        output[class_type] = {\"c\": class_count/len(labels)}\n",
    "        # calculate the conditional probabilities for each attribute/value combination given the current class\n",
    "        for index, attribute in enumerate(attributes):\n",
    "            unique_values = set([row[index] for row in data])\n",
    "            for value in unique_values:\n",
    "                value_count = sum(1 for row_index, row in enumerate(data) \n",
    "                                if row[index] == value and labels[row_index] == class_type)\n",
    "                prob = (value_count+smoothing_factor)/(class_count+smoothing_factor)\n",
    "                if attribute not in output[class_type]:\n",
    "                    output[class_type][attribute] = {}\n",
    "                output[class_type][attribute][value] = prob\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asserions/unit tests\n",
    "test_data_1 = [\n",
    "    [\"round\", \"large\", \"blue\"],\n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"blue\"],  \n",
    "    [\"round\", \"small\", \"red\"],  \n",
    "    [\"square\", \"small\", \"green\"],  \n",
    "    [\"round\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"large\", \"red\"],  \n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"round\", \"large\", \"red\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "    [\"round\", \"small\", \"green\"]\n",
    "]\n",
    "\n",
    "test_labels_1 = [\"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"no\"]\n",
    "\n",
    "expected_output = {'no': {'c': 0.5333333333333333, \n",
    "                          'shape': {'round': 0.4444444444444444, 'square': 0.6666666666666666}, \n",
    "                          'size': {'small': 0.7777777777777778, 'large': 0.3333333333333333}, \n",
    "                          'color': {'blue': 0.4444444444444444, 'red': 0.4444444444444444, 'green': 0.3333333333333333}}, \n",
    "                   'yes': {'c': 0.4666666666666667, \n",
    "                           'shape': {'round': 0.625, 'square': 0.5}, \n",
    "                           'size': {'small': 0.25, 'large': 0.875}, \n",
    "                           'color': {'blue': 0.125, 'red': 0.5, 'green': 0.625}}}\n",
    "\n",
    "assert train_naive_bayes(test_data_1, test_labels_1, [\"shape\", \"size\", \"color\"]) == expected_output\n",
    "\n",
    "test_data_2 = [\n",
    "    [\"round\", \"large\", \"blue\"],\n",
    "    [\"square\", \"large\", \"green\"],  \n",
    "    [\"square\", \"small\", \"red\"],  \n",
    "]\n",
    "\n",
    "test_labels_2 = [\"no\", \"yes\", \"no\"]\n",
    "\n",
    "expected_output_2 = {'yes': \n",
    "                     {'c': 0.3333333333333333, \n",
    "                      'shape': {'round': 0.5, 'square': 1.0}, \n",
    "                      'size': {'large': 1.0, 'small': 0.5}, \n",
    "                      'color': {'blue': 0.5, 'green': 1.0, 'red': 0.5}}, \n",
    "                     'no': \n",
    "                     {'c': 0.6666666666666666, \n",
    "                      'shape': {'round': 0.6666666666666666, 'square': 0.6666666666666666}, \n",
    "                      'size': {'large': 0.6666666666666666, 'small': 0.6666666666666666}, \n",
    "                      'color': {'blue': 0.6666666666666666, 'green': 0.3333333333333333, 'red': 0.6666666666666666}}}\n",
    "\n",
    "assert train_naive_bayes(test_data_2, test_labels_2, [\"shape\", \"size\", \"color\"]) == expected_output_2\n",
    "\n",
    "test_data_3 = []\n",
    "test_labels_3 = []\n",
    "\n",
    "assert train_naive_bayes(test_data_3, test_labels_3, [\"shape\", \"size\", \"color\"]) == {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"normalize\"></a>\n",
    "## normalize\n",
    "*The normalize function normalizes the probabilities calculated by the classify_observation function.*\n",
    "**Used by**: [classify_observation](#classify_observation)\n",
    "\n",
    "* **results** Dict[str, float] | str: a dictionary of predicted probabilities for each class label\n",
    "\n",
    "**returns** Dict[str, float]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(results: dict[str, float]) -> Dict[str, float]:\n",
    "    new_results = {}\n",
    "    for key, value in results.items():\n",
    "        values = results.values()\n",
    "        new_results[key] = value/sum(values)\n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_results_1 = {\"yes\": 0.0006, \"no\": 0.0432}\n",
    "result_1 = normalize(test_results_1)\n",
    "assert round(sum(list(result_1.values())), 2) == 1.00\n",
    "\n",
    "test_results_2 = {\"yes\": 0.0001, \"no\": 0}\n",
    "result_2 = normalize(test_results_2)\n",
    "assert round(sum(list(result_2.values())), 2) == 1.00\n",
    "\n",
    "test_results_3 = {\"yes\": 0.0000, \"no\": 0.99}\n",
    "result_3 = normalize(test_results_3)\n",
    "assert round(sum(list(result_3.values())), 2) == 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify_observation\"></a>\n",
    "## classify_observation\n",
    "*The classify_observation algorithm uses the probabilities for the Naive Bayes Classifier to find the classification for a single observation. The function makes these classifications by creating a dictionary that represents each class's probability given the observation's characteristics. The probability of each class is calculated by multiplying the probability of the class by the conditional probabilities of the attribute value for the class for each value in the observation.*\n",
    "\n",
    "*Ex: (\"round\", \"small\", \"red\") would produce the following calculations for class labels yes and no:*\n",
    "\n",
    "**probability of yes**: p(yes) * p(round | yes) * p(small | yes) * p(red | yes)\n",
    "\n",
    "**probability of no**: p(no) * p(round | no) * p(small | no) * p(red | no)\n",
    "\n",
    "*The function then returns a tuple containing the prediction in the first position (the class label with the highest probability) and a dictionary of probabilities for each class label in the second position.*\n",
    "\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **probs** Dict[str, Any]: the probabilities returned by the [train_naive_bayes](#train_naive_bayes) function.\n",
    "* **attributes** List[str]: the attributes in the dataset (excluding class label)\n",
    "* **observation** List[str]: the labeled or unlabeled observation to classify\n",
    "\n",
    "**returns** Tuple[str, Dict[str, float]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_observation(probs: Dict[str, Any], attributes: List[str], observation: List[str]) -> Tuple[str, Dict[str, float]]:\n",
    "    results = {}\n",
    "    for label in probs.keys():\n",
    "        prob_class = probs[label][\"c\"]\n",
    "        for index, value in enumerate(observation):\n",
    "            prob_class *= probs[label][attributes[index]][value]\n",
    "            results[label] = prob_class\n",
    "    norm_results = normalize(results)\n",
    "    # get the dictionary key with the highest value\n",
    "    best = max(norm_results, key=norm_results.get)\n",
    "    return (best, norm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_probs = {'no': {'c': 0.533, \n",
    "                          'shape': {'round': 0.444, 'square': 0.667}, \n",
    "                          'size': {'small': 0.778, 'large': 0.333}, \n",
    "                          'color': {'blue': 0.444, 'red': 0.444, 'green': 0.333}}, \n",
    "               'yes': {'c': 0.467, \n",
    "                       'shape': {'round': 0.625, 'square': 0.5}, \n",
    "                       'size': {'small': 0.25, 'large': 0.875}, \n",
    "                       'color': {'blue': 0.125, 'red': 0.5, 'green': 0.625}}}\n",
    "\n",
    "test_instance_1 = [\"square\", \"large\", \"red\"]\n",
    "results_1 = classify_observation(test_probs, [\"shape\", \"size\", \"color\"], test_instance_1)\n",
    "assert results_1 == ('yes', {'no': 0.33973153417458696, 'yes': 0.6602684658254131})\n",
    "# confirm that the normalized probabilities equal 1\n",
    "assert round(results_1[1][\"yes\"] + results_1[1][\"no\"], 2) == 1.00\n",
    "\n",
    "test_instance_2 = [\"round\", \"small\", \"blue\"]\n",
    "results_2 = classify_observation(test_probs, [\"shape\", \"size\", \"color\"], test_instance_2)\n",
    "assert results_2 == ('no', {'no': 0.8996228935625692, 'yes': 0.10037710643743075})\n",
    "# confirm that the normalized probabilities equal 1\n",
    "assert round(results_2[1][\"yes\"] + results_2[1][\"no\"], 2) == 1.00\n",
    "\n",
    "# unseen example\n",
    "test_instance_3 = [\"square\", \"large\", \"blue\"]\n",
    "results_3 = classify_observation(test_probs, [\"shape\", \"size\", \"color\"], test_instance_3)\n",
    "assert results_3 == ('no', {'no': 0.673004045771441, 'yes': 0.326995954228559})\n",
    "# confirm that the normalized probabilities equal 1\n",
    "assert round(results_3[1][\"yes\"] + results_3[1][\"no\"], 2) == 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "*The classify function takes a list of labeled or unlabeled data and returns predictions by calling [classify_observation](#classify_observation) for each value.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **probs** Dict[str, Any] | str: the probabilities for the Naive Bayes Classifier represented as nested dictionaries\n",
    "* **observations** List[List[str]]: the labeled or unlabeled observations to classify\n",
    "* **attributes** List[str]: the attributes in the dataset (excluding class label)\n",
    "\n",
    "**returns** List[Tuple[str, Dict[str, float]]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(probs: Dict[str, Any], observations: List[List[str]], attributes: List[str]) -> List[Tuple[str, Dict[str, float]]]:\n",
    "    classifications = []\n",
    "    for observation in observations:\n",
    "        predicition = classify_observation(probs, attributes, observation)\n",
    "        classifications.append(predicition)\n",
    "    return classifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "test_probs = {'no': {'c': 0.533, \n",
    "                          'shape': {'round': 0.444, 'square': 0.667}, \n",
    "                          'size': {'small': 0.778, 'large': 0.333}, \n",
    "                          'color': {'blue': 0.444, 'red': 0.444, 'green': 0.333}}, \n",
    "               'yes': {'c': 0.467, \n",
    "                       'shape': {'round': 0.625, 'square': 0.5}, \n",
    "                       'size': {'small': 0.25, 'large': 0.875}, \n",
    "                       'color': {'blue': 0.125, 'red': 0.5, 'green': 0.625}}}\n",
    "\n",
    "test_instances_1 = [[\"square\", \"large\", \"red\"], [\"round\", \"large\", \"blue\"], [\"square\", \"small\", \"blue\"]]\n",
    "expected_output_1 = [('yes', \n",
    "                    {'no': 0.33973153417458696, \n",
    "                     'yes': 0.6602684658254131}), \n",
    "                   ('no', \n",
    "                    {'no': 0.5229075788819071, \n",
    "                     'yes': 0.4770924211180929}), \n",
    "                   ('no', \n",
    "                    {'no': 0.9439140906419522, \n",
    "                     'yes': 0.05608590935804781})]\n",
    "\n",
    "assert classify(test_probs, test_instances_1, [\"shape\", \"size\", \"color\"]) == expected_output_1\n",
    "\n",
    "# test with one example\n",
    "test_instances_2 = [[\"square\", \"large\", \"red\"]]\n",
    "expected_output_2 = [('yes', \n",
    "                    {'no': 0.33973153417458696, \n",
    "                     'yes': 0.6602684658254131})]\n",
    "\n",
    "assert classify(test_probs, test_instances_2, [\"shape\", \"size\", \"color\"]) == expected_output_2\n",
    "\n",
    "# test with no examples\n",
    "assert classify(test_probs, [], [\"shape\", \"size\", \"color\"]) == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"error_rate\"></a>\n",
    "## error_rate\n",
    "*The error_rate function takes a list of predictions and a list of true values and returns the error rate of the predictions using the formula incorrect_predicitions/total_predictions.*\n",
    "**Used by**: [k_fold_validation](#k_fold_validation)\n",
    "\n",
    "* **predictions** List[str]: the predictions for a classification task\n",
    "* **labels** List[str]: the true class values\n",
    "\n",
    "**returns** float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions: List[str], labels: List[str]) -> float:\n",
    "    total = len(predictions)\n",
    "    incorrect = sum(pred != true_value for pred, true_value in zip(predictions, labels))\n",
    "    return incorrect / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "classifications_1 = [\"yes\", \"no\", \"yes\"]\n",
    "labels_1 = [\"yes\", \"no\", \"yes\"]\n",
    "\n",
    "assert error_rate(classifications_1, labels_1) == 0.00\n",
    "\n",
    "classifications_2 = [\"yes\", \"yes\", \"yes\"]\n",
    "labels_2 = [\"no\", \"no\", \"no\"]\n",
    "\n",
    "assert error_rate(classifications_2, labels_2) == 1.00\n",
    "\n",
    "classifications_3 = [\"no\", \"no\", \"yes\", \"yes\"]\n",
    "labels_3 = [\"no\", \"no\", \"no\", \"no\"]\n",
    "\n",
    "assert error_rate(classifications_3, labels_3) == 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k_fold_validation\"></a>\n",
    "## k_fold_validation\n",
    "\n",
    "*The k_fold_validation function applies k-fold validation on the dataset and prints the average error and error variance of the training and test set for each run. The algorithm returns the average error and the error variance for the training and test sets. The function also prints these values. The k-fold validation algorithm works by sampling k unique test samples from the dataset and using the rest of the data for a training set. This algorithm helps evaluate small datasets.*\n",
    "\n",
    "* **model_function** Callable: the algorithm for the model\n",
    "* **classify_function** Callable: the classification function\n",
    "* **eval_function** Callable: the evaluation function\n",
    "* **label_index** int: the label index in the dataset\n",
    "* **folds** List[List[List[str]]]: the k folds to evaluate\n",
    "* **attributes** List[str]: the data attributes (excluding class label)\n",
    "* **smoothing** bool: specifies whether the training function for the Naive Bayes Classifier should use +1 smoothing\n",
    "\n",
    "**returns** Tuple[Any]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(model_function: Callable, classify_function: Callable, eval_function: Callable, label_index: int, folds: List[List[List[str]]], attributes: List[str], smoothing:bool=True) -> Tuple[Any]:\n",
    "    total_train_loss, total_test_loss = 0, 0\n",
    "    train_losses, test_losses = [], []\n",
    "    for index in range(len(folds)):\n",
    "        # split data and labels\n",
    "        train, test = create_train_test(folds, index)\n",
    "        train_examples, train_labels = split_labels(train, label_index)\n",
    "        test_examples, test_labels = split_labels(test, label_index)\n",
    "        # train model\n",
    "        model = model_function(train_examples, train_labels, attributes, smoothing)\n",
    "        # classify\n",
    "        train_predictions = classify_function(model, train_examples, attributes)\n",
    "        train_loss = eval_function([row[0] for row in train_predictions], train_labels)\n",
    "        test_predictions = classify_function(model, test_examples, attributes)\n",
    "        test_loss = eval_function([row[0] for row in test_predictions], test_labels)\n",
    "        print(f\"Fold: {index+1}, train loss: {round(train_loss*100, 2)}%, test loss: {round(test_loss*100, 2)}%\")\n",
    "        total_train_loss += train_loss\n",
    "        train_losses.append(train_loss)\n",
    "        total_test_loss += test_loss\n",
    "        test_losses.append(test_loss)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"Average Train Loss: {round((total_train_loss/len(folds)) * 100, 2)}%, Train Loss Variance: {np.var(train_losses)}\")\n",
    "    print(f\"Average Test Loss: {round((total_test_loss/len(folds)) * 100, 2)}%, Test Loss Variance: {np.var(test_losses)}\")\n",
    "    return total_train_loss/len(folds), np.var(train_losses), total_test_loss/len(folds), np.var(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train loss: 15.38%, test loss: 50.0%\n",
      "Fold: 2, train loss: 15.38%, test loss: 0.0%\n",
      "Fold: 3, train loss: 23.08%, test loss: 0.0%\n",
      "Fold: 4, train loss: 7.69%, test loss: 50.0%\n",
      "Fold: 5, train loss: 15.38%, test loss: 0.0%\n",
      "Fold: 6, train loss: 14.29%, test loss: 100.0%\n",
      "Fold: 7, train loss: 14.29%, test loss: 0.0%\n",
      "Fold: 8, train loss: 14.29%, test loss: 0.0%\n",
      "Fold: 9, train loss: 14.29%, test loss: 0.0%\n",
      "Fold: 10, train loss: 14.29%, test loss: 100.0%\n",
      "---------------------------------------------------\n",
      "Average Train Loss: 14.84%, Train Loss Variance: 0.0012136215432918733\n",
      "Average Test Loss: 30.0%, Test Loss Variance: 0.16\n"
     ]
    }
   ],
   "source": [
    "# assertions/unit tests\n",
    "test_data = [\n",
    "    [\"round\", \"large\", \"blue\", \"no\"],\n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"red\", \"no\"],  \n",
    "    [\"round\", \"large\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"blue\", \"no\"],  \n",
    "    [\"round\", \"small\", \"blue\", \"no\"],  \n",
    "    [\"round\", \"small\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"green\", \"no\"],  \n",
    "    [\"round\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"square\", \"large\", \"red\", \"no\"],  \n",
    "    [\"square\", \"large\", \"green\", \"yes\"],  \n",
    "    [\"round\", \"large\", \"red\", \"yes\"],  \n",
    "    [\"square\", \"small\", \"red\", \"no\"],  \n",
    "    [\"round\", \"small\", \"green\", \"no\"]\n",
    "]\n",
    "test_attributes = [\"shape\", \"size\", \"color\"]\n",
    "\n",
    "folds = create_folds(test_data, 10)\n",
    "average_train_error, train_variance,  average_test_error, test_variance = k_fold_validation(train_naive_bayes, classify, error_rate, 3, folds, test_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier with the Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column labels\n",
    "col_names = [\"label\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises?\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \n",
    "             \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\",\n",
    "            \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"]\n",
    "# read in data\n",
    "def read_data(filename, delimiter):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.strip().split(delimiter) for line in f]\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "data = read_data('Datasets/agaricus-lepiota.data', \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Validation with +1 Smoothing\n",
      "---------------------------------------------------\n",
      "Fold: 1, train loss: 4.43%, test loss: 5.04%\n",
      "Fold: 2, train loss: 4.36%, test loss: 4.67%\n",
      "Fold: 3, train loss: 4.47%, test loss: 4.31%\n",
      "Fold: 4, train loss: 4.45%, test loss: 4.8%\n",
      "Fold: 5, train loss: 4.5%, test loss: 4.68%\n",
      "Fold: 6, train loss: 4.47%, test loss: 4.31%\n",
      "Fold: 7, train loss: 4.28%, test loss: 3.57%\n",
      "Fold: 8, train loss: 4.53%, test loss: 4.56%\n",
      "Fold: 9, train loss: 4.58%, test loss: 4.68%\n",
      "Fold: 10, train loss: 4.55%, test loss: 4.56%\n",
      "---------------------------------------------------\n",
      "Average Train Loss: 4.46%, Train Loss Variance: 7.242277321830525e-07\n",
      "Average Test Loss: 4.52%, Test Loss Variance: 1.4177094278540854e-05\n"
     ]
    }
   ],
   "source": [
    "new_folds = create_folds(data, 10)\n",
    "print(\"10-fold Validation with +1 Smoothing\")\n",
    "print(\"---------------------------------------------------\")\n",
    "averge_train_error, train_variance, averge_test_error, test_variance = k_fold_validation(train_naive_bayes, classify, error_rate, 0, new_folds, col_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Validation without Smoothing\n",
      "---------------------------------------------------\n",
      "Fold: 1, train loss: 0.26%, test loss: 0.62%\n",
      "Fold: 2, train loss: 0.27%, test loss: 0.12%\n",
      "Fold: 3, train loss: 0.27%, test loss: 0.25%\n",
      "Fold: 4, train loss: 0.26%, test loss: 0.37%\n",
      "Fold: 5, train loss: 0.3%, test loss: 0.25%\n",
      "Fold: 6, train loss: 0.3%, test loss: 0.37%\n",
      "Fold: 7, train loss: 0.37%, test loss: 0.37%\n",
      "Fold: 8, train loss: 0.33%, test loss: 0.37%\n",
      "Fold: 9, train loss: 0.27%, test loss: 0.37%\n",
      "Fold: 10, train loss: 0.3%, test loss: 0.12%\n",
      "---------------------------------------------------\n",
      "Average Train Loss: 0.29%, Train Loss Variance: 1.0559665571808295e-07\n",
      "Average Test Loss: 0.32%, Test Loss Variance: 1.8767830513330512e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Validation without Smoothing\")\n",
    "print(\"---------------------------------------------------\")\n",
    "averge_train_error, train_variance, averge_test_error, test_variance = k_fold_validation(train_naive_bayes, classify, error_rate, 0, new_folds, col_names[1:], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Results\n",
    "The Naive Bayes Classifier performed better without smoothing than it did with smoothing. The model had around 96% accuracy when tested with Laplace smoothing. The model had about 99% accuracy when tested without smoothing. These results could indicate that the training and test sets were very similar for the mushroom dataset. Smoothing is beneficial when the test set contains many unseen observations because probabilities of 0 could negate the other, possibly valuable, feature probabilities used in the multiplier of the classification equation. If the examples in the test set are captured in the training set, Laplace smoothing could introduce noise. The model that applied Laplace smoothing might perform better than the non-smoothing model for a test set containing mushrooms that were not represented in the training set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
